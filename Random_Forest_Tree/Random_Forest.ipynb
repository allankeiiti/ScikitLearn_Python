{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Uma árvore de decisão tem como objetivo principal identificar quais atributos ficarão na parte superior da árvore, então ela identifica uma variável/atributo em um dataset onde, dividindo o dataset por este atributo, crie ramificações que permite diminuir a dúvida/incerteza na tomada de uma decisão, porém caso haja uma alteração na base de dados a estrutura da árvore se altera, portanto existe as árvores aleatórias, portando a Random Forest é uma evolução das Árvores de decisão. \n",
    "\n",
    "Podemos determinar quantas árvores independentes entre si podem ser utilizadas no modelo\n",
    "\n",
    "O RF segue a lógica do *Emsemble Learning* ou seja, aprendizagem em conjunto. Na vida real, seria como consultar diversos especialistas da área para a tomada de uma decisão ou \"Vários algoritmos juntos para construir um algoritmo mais forte\".\n",
    "\n",
    "Como um exemplo da vida real, a resposta mais votada pelos especialistas é a decisão a ser tomada (Classificação) ou considerando a média de respostas (Regressão)\n",
    "\n",
    "Portando, a Random Forest é um algoritmo tanto para classificação quanto para a regressão\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png)\n",
    "\n",
    "Na RF é necessário decidir quais variáveis/atributos deixar no dataset, já que aqueles que não contribuem o suficiente para \n",
    "resolução do problema pode acarretar em *overfitting*\n",
    "\n",
    "### Hiperparâmetros\n",
    "\n",
    "- n_estimators: Número de árvores construídas pelo algoritmo. maior quantidade melhor predição porém maior consumo de recurso de computação causando lentidões.\n",
    "- max_features: Número máximo de variáveis/atributos a serem utilizados.\n",
    "- min_sample_leaf: Número mínio de folhas para cada árvore.\n",
    "- criterion: Mede a qualidade da divisão por folhas.\n",
    "             gini - Gini impurity.\n",
    "             entropy - Ganho de informação - caracterizada como pureza ou impureza na base de dados, medindo quão organizados ou desorganizados eles estão.\n",
    "- n_jobs: Número de quantos processadores o algoritmo pode utilizar, default=1 e -1 não limita o uso de processadores.\n",
    "- random_state: Útil para reproduzir os mesmos resultados, recebe um inteiro como parâmetro, logo se ser inserido 42 sempre o resultado será o mesmo quando passar 42 como random_state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências:\n",
    "<a href=\"\n",
    "https://medium.com/machina-sapiens/o-algoritmo-da-floresta-aleat%C3%B3ria-3545f6babdf8#:~:text=Floresta%20Aleat%C3%B3ria%20(random%20forest)%20%C3%A9%20um%20algoritmo%20de%20aprendizagem%20supervisionada.&text=Dizendo%20de%20modo%20simples%3A%20o,maior%20acur%C3%A1cia%20e%20mais%20est%C3%A1vel.\">Medium - Aprendendo em uma Floresta Aleatória</a>\n",
    "\n",
    "<a href=\"https://www.udemy.com/course/machine-learning-e-data-science-com-python-y/\">Curso de Machine Learning da Udemy</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
